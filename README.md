# Assistive Blink Control - Proof of Concept (PoC)

[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/soyunomas/assistive-blink-control-poc/blob/main/LICENSE) <!-- ¬°Aseg√∫rate de a√±adir un archivo LICENSE con la licencia MIT! -->
[![Status](https://img.shields.io/badge/status-Proof%20of%20Concept-orange)](.)
[![Demo](https://img.shields.io/badge/Demo-Live-brightgreen)](https://soyunomas.github.io/assistive-blink-control-poc/parpadeo.html)

Una aplicaci√≥n web experimental (Prueba de Concepto) que demuestra c√≥mo se puede usar la detecci√≥n de parpadeos a trav√©s de la webcam para interactuar con una interfaz de comunicaci√≥n asistencial b√°sica. Permite a los usuarios navegar por categor√≠as y seleccionar palabras predefinidas utilizando √∫nicamente el parpadeo.

**Proyecto en GitHub:** [https://github.com/soyunomas/assistive-blink-control-poc/](https://github.com/soyunomas/assistive-blink-control-poc/)

**Demo en vivo:** [https://soyunomas.github.io/assistive-blink-control-poc/parpadeo.html](https://soyunomas.github.io/assistive-blink-control-poc/parpadeo.html)

*(Nota importante: Se requiere una webcam y permitir el acceso a la c√°mara en el navegador para que la demo funcione. Se recomienda usar HTTPS para mayor compatibilidad y seguridad, aunque la demo pueda funcionar en localhost o `file://`)*

![Screenshot de la interfaz](screenshot.png)

---

## ‚ú® Caracter√≠sticas Clave

*   **Control por Parpadeo:** Utiliza la webcam y **MediaPipe FaceLandmarker** para detectar los parpadeos del usuario en tiempo real.
*   **Navegaci√≥n Jer√°rquica Simple:**
    *   Permite seleccionar entre diferentes categor√≠as de palabras (Respuestas, Necesidades, Sensaciones, etc.).
    *   Dentro de una categor√≠a, permite seleccionar palabras espec√≠ficas.
    *   Incluye una opci√≥n "Volver Atr√°s" para regresar de la lista de palabras a la lista de categor√≠as.
*   **Interacci√≥n Diferenciada por Duraci√≥n del Parpadeo:**
    *   **Parpadeo Corto:** Funciona como "Siguiente", moviendo el resaltado al siguiente √≠tem en la lista activa (categor√≠a o palabra).
    *   **Parpadeo Largo:** Funciona como "Seleccionar", eligiendo el √≠tem resaltado (entra en una categor√≠a, selecciona una palabra final, o activa la opci√≥n "Volver Atr√°s").
*   **Feedback Visual Claro:**
    *   Resalta visualmente el elemento actualmente enfocable (`.selected-item-highlight`).
    *   Muestra la palabra final seleccionada en un √°rea prominente (`#selected-word-display`).
    *   Muestra el feed de la c√°mara en un recuadro fijo para que el usuario pueda verificar su posici√≥n y la detecci√≥n.
*   **Sensibilidad de Detecci√≥n Ajustable:**
    *   Incluye un slider (`#sensitivity-slider`) que permite al usuario ajustar el umbral de detecci√≥n de parpadeo (Eye Aspect Ratio - EAR). Esto ayuda a adaptar la aplicaci√≥n a diferentes usuarios, condiciones de iluminaci√≥n o fatiga.
*   **Interfaz Limpia y Adaptable:**
    *   Dise√±o basado en **Bootstrap 5** para una apariencia moderna y consistencia.
    *   Incluye reglas CSS (`@media`) para mejorar la usabilidad en pantallas m√°s peque√±as (m√≥viles y tablets).
*   **Manejo B√°sico de Errores:** Muestra mensajes al usuario si no se detecta la c√°mara, se deniegan los permisos, o falla la inicializaci√≥n de MediaPipe.

## ‚öôÔ∏è C√≥mo Funciona Detalladamente

1.  **Inicializaci√≥n:** Al cargar la p√°gina (`DOMContentLoaded`), la aplicaci√≥n inicializa la interfaz, configura el slider de sensibilidad y llama a `createFaceLandmarker`.
2.  **Creaci√≥n del Detector Facial:** Se instancia `FaceLandmarker` de `@mediapipe/tasks-vision` (versi√≥n `0.10.22-rc.20250304` en el c√≥digo), configurado para ejecutarse en modo `VIDEO` y detectar una sola cara, preferiblemente usando la GPU (`delegate: "GPU"`).
3.  **Acceso a la C√°mara:** Utiliza `navigator.mediaDevices.getUserMedia` para solicitar acceso a la webcam, pidiendo idealmente una resoluci√≥n de 640x480 y la c√°mara frontal (`facingMode: 'user'`). Gestiona posibles errores comunes (`NotAllowedError`, `NotFoundError`, etc.).
4.  **Inicio del Procesamiento:** Una vez que el stream de video est√° listo (`loadeddata`), se inicia el bucle de predicci√≥n `predictWebcam` usando `requestAnimationFrame`.
5.  **Bucle de Detecci√≥n (`predictWebcam`):**
    *   En cada frame, se pasa el frame actual del video a `faceLandmarker.detectForVideo()`.
    *   Si se detectan landmarks faciales, se extraen las coordenadas 3D de los puntos clave de ambos ojos (usando `LEFT_EYE_INDICES` y `RIGHT_EYE_INDICES`).
    *   Se calcula el **Eye Aspect Ratio (EAR)** para cada ojo usando la distancia euclidiana entre puntos verticales y horizontales. El EAR promedio de ambos ojos se utiliza como m√©trica principal. `EAR = (DistanciaVertical1 + DistanciaVertical2) / (2 * DistanciaHorizontal)`. Un EAR bajo significa que el ojo est√° m√°s cerrado.
    *   **L√≥gica de Detecci√≥n de Parpadeo:**
        *   Si `avgEAR < EYE_AR_THRESH` (el umbral ajustado por el slider): Se incrementa un contador (`blinkCounter`). Se marca que un parpadeo est√° en curso (`isBlinking = true`).
        *   Si `avgEAR >= EYE_AR_THRESH` (ojo abierto) y `isBlinking` era `true`: Se eval√∫a `blinkCounter`:
            *   Si `blinkCounter > LONG_BLINK_THRESHOLD` (actualmente 12 frames): Se interpreta como **PARPADEO LARGO (Selecci√≥n)**. La acci√≥n depende del modo (`CATEGORY` o `WORD`): seleccionar categor√≠a y mostrar palabras, seleccionar palabra final y mostrarla (volviendo luego a categor√≠as), o activar "Volver Atr√°s".
            *   Si `blinkCounter >= EYE_AR_CONSEC_FRAMES` (actualmente 2 frames) pero no es largo: Se interpreta como **PARPADEO CORTO (Navegaci√≥n)**. Se avanza al siguiente elemento en la lista activa (`selectedCategoryIndex` o `selectedWordIndex` se incrementan modularmente).
        *   El contador y el flag `isBlinking` se resetean despu√©s de detectar y procesar el final de un parpadeo.
6.  **Actualizaci√≥n de la Interfaz:** Las funciones `displayCategories()` y `displayWords()` se llaman despu√©s de detectar un parpadeo para actualizar qu√© lista se muestra y qu√© elemento est√° resaltado. La funci√≥n `scrollIntoView()` se usa para mantener visible el elemento seleccionado. El texto seleccionado se muestra en `#selected-word-display`.
7.  **Optimizaci√≥n:** Se evita procesar el mismo frame de video m√∫ltiples veces comprobando `video.currentTime === lastVideoTime`.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

*   **HTML5:** Estructura sem√°ntica del documento.
*   **CSS3:** Estilos personalizados (incluyendo `position: fixed`, `transform`, `transition`, `box-shadow`) y dise√±o adaptable (`@media` queries).
*   **Bootstrap 5.3.2:** Framework CSS/JS utilizado principalmente para layout (contenedor, centrado), componentes b√°sicos (botones impl√≠citos en los spans) y estilos generales. Se carga desde CDN.
*   **JavaScript (ES Modules):**
    *   Toda la l√≥gica de la aplicaci√≥n.
    *   Manipulaci√≥n del DOM (creaci√≥n de elementos, gesti√≥n de clases, actualizaci√≥n de contenido).
    *   Manejo de eventos (slider `input`, video `loadeddata`, `error`).
    *   Uso de APIs del navegador: `navigator.mediaDevices.getUserMedia`, `requestAnimationFrame`, `performance.now()`.
*   **MediaPipe Tasks Vision (`@mediapipe/tasks-vision@0.10.22-rc.20250304/+esm`):**
    *   Librer√≠a de Google para tareas de visi√≥n por computadora.
    *   Se utiliza `FaceLandmarker` para la detecci√≥n de puntos clave faciales en tiempo real.
    *   Se carga directamente desde la CDN de `jsdelivr.net`.

## üöÄ Uso de la Demo

1.  Abre el enlace de la **[Demo en vivo](https://soyunomas.github.io/assistive-blink-control-poc/parpadeo.html)** en un navegador web moderno (se recomiendan las √∫ltimas versiones de Chrome, Firefox o Edge).
2.  **Requisitos:**
    *   Necesitas una **webcam** conectada y funcional.
    *   El navegador debe soportar `getUserMedia` y las tecnolog√≠as necesarias para MediaPipe (WebAssembly, WebGL).
3.  **Permisos:** Cuando el navegador lo solicite, **permite** que el sitio acceda a tu c√°mara. Si lo bloqueas accidentalmente, necesitar√°s ajustar los permisos del sitio en la configuraci√≥n del navegador y recargar la p√°gina.
4.  **Interacci√≥n:**
    *   Una vez cargado, ver√°s el video de tu c√°mara en la parte superior y la lista de categor√≠as.
    *   **Mira directamente a la c√°mara.**
    *   Realiza un **parpadeo corto y natural** (cerrar y abrir los ojos r√°pidamente) para mover el resaltado azul (`selected-item-highlight`) al siguiente elemento de la lista.
    *   Realiza un **parpadeo largo** (mant√©n los ojos cerrados durante aproximadamente medio segundo o un poco m√°s) para seleccionar el elemento resaltado.
    *   Si la detecci√≥n no es fiable (detecta demasiados parpadeos o muy pocos), ajusta el slider de **"Sensibilidad Parpadeo"**:
        *   *Mover hacia la izquierda (valores m√°s bajos)*: Requiere cerrar m√°s los ojos para detectar el parpadeo (menos sensible).
        *   *Mover hacia la derecha (valores m√°s altos)*: Detecta parpadeos m√°s leves (m√°s sensible). Encuentra el valor que mejor funcione para ti.
5.  **Navega:** Usa parpadeos largos para entrar en categor√≠as, seleccionar palabras o volver atr√°s. Usa parpadeos cortos para ciclar entre las opciones disponibles. La palabra seleccionada aparecer√° en el cuadro verde inferior.

## ‚ö†Ô∏è Limitaciones y Naturaleza PoC (Importante)

*   **Prueba de Concepto:** Esta aplicaci√≥n es una demostraci√≥n t√©cnica y **no est√° dise√±ada ni probada para un uso asistencial real o cr√≠tico**. Es una exploraci√≥n de la tecnolog√≠a.
*   **Dependencia de Condiciones:**
    *   **Iluminaci√≥n:** La precisi√≥n de MediaPipe y la detecci√≥n de EAR pueden verse muy afectadas por la luz ambiental (demasiado oscura, demasiado brillante, contraluz).
    *   **Posici√≥n y √Ångulo:** Funciona mejor cuando la cara est√° bien iluminada y relativamente de frente a la c√°mara. Movimientos bruscos o √°ngulos extremos pueden fallar.
    *   **Gafas:** Dependiendo del tipo de gafas y los reflejos, la detecci√≥n de los ojos puede ser menos precisa.
*   **Variabilidad del Usuario:** La forma "normal" de parpadear, la forma de los ojos y la fatiga var√≠an mucho entre personas. El ajuste de sensibilidad es crucial pero puede no ser suficiente para todos.
*   **Rendimiento:** El procesamiento de video en tiempo real con MediaPipe consume recursos de CPU y/o GPU. El rendimiento puede variar dr√°sticamente seg√∫n el hardware del dispositivo. En dispositivos de baja potencia, puede haber retrasos o baja tasa de frames.
*   **Falsos Positivos/Negativos:** Es posible que la aplicaci√≥n detecte parpadeos que no ocurrieron (especialmente con mala iluminaci√≥n o movimientos r√°pidos) o que no detecte parpadeos reales (si son muy r√°pidos o no lo suficientemente pronunciados seg√∫n el umbral).
*   **Vocabulario Fijo:** Las categor√≠as y palabras est√°n codificadas directamente en el archivo JavaScript. No hay forma de personalizarlas a trav√©s de la interfaz.
*   **Sin Persistencia:** Cualquier selecci√≥n se pierde al recargar la p√°gina.

## üí° Posibles Mejoras Futuras

*   **Calibraci√≥n por Usuario:** Una rutina inicial para ajustar autom√°ticamente los umbrales de EAR y duraci√≥n de parpadeo a cada individuo.
*   **Feedback Auditivo:** A√±adir sonidos para confirmar la navegaci√≥n y selecci√≥n, mejorando la accesibilidad.
*   **Personalizaci√≥n del Vocabulario:** Permitir a los usuarios (o cuidadores) a√±adir/editar/eliminar categor√≠as y palabras.
*   **Modo "Escritura Libre":** Explorar m√©todos para seleccionar letras individuales (p. ej., mediante escaneo de filas/columnas) para formar palabras personalizadas.
*   **Robustez Mejorada:** Investigar t√©cnicas para mitigar el impacto de la iluminaci√≥n variable, el uso de gafas y los diferentes √°ngulos de la cabeza.
*   **Detecci√≥n de Otros Gestos:** Ampliar la interacci√≥n usando otros puntos faciales detectables por MediaPipe (movimiento de cejas, apertura de boca, etc.), si es apropiado para el caso de uso.
*   **Integraci√≥n con S√≠ntesis de Voz (TTS):** Hacer que la palabra seleccionada sea le√≠da en voz alta.
*   **Mejoras de Accesibilidad (WCAG):** Realizar una auditor√≠a y aplicar mejoras para cumplir con est√°ndares de accesibilidad web.

## üìÑ Licencia

Este proyecto est√° distribuido bajo la Licencia MIT. Consulta el archivo `LICENSE` en el repositorio para m√°s detalles.

---

*Desarrollado por [soyunomas](https://github.com/soyunomas)*
